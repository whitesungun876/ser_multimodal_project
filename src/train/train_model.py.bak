import os
import argparse
import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split

from models.audio.cnn_model         import CNNModel
from models.text.transformer_model  import TransformerModel
from utils.dataset_loader           import get_dataloaders
from evaluation.metrics             import compute_metrics

def parse_args():
    p = argparse.ArgumentParser("Train SER multimodal model")
    p.add_argument("--fusion_data", type=str,
                   default="data/early_fused_aligned/X.npy",
                   help="Path to fused feature file (X.npy)")
    p.add_argument("--labels", type=str,
                   default="data/early_fused_aligned/y.npy",
                   help="Path to labels file (y.npy)")
    p.add_argument("--model_type", type=str, choices=["cnn", "transformer"],
                   default="cnn", help="Which model to train")
    p.add_argument("--save_dir", type=str, default="checkpoints",
                   help="Directory to save checkpoints")
    p.add_argument("--epochs", type=int, default=20,
                   help="Number of epochs")
    p.add_argument("--batch_size", type=int, default=32,
                   help="Batch size")
    p.add_argument("--lr", type=float, default=1e-4,
                   help="Learning rate")
    p.add_argument("--num_classes", type=int, default=4,
                   help="Number of emotion classes")
    return p.parse_args()

def train(args):
    os.makedirs(args.save_dir, exist_ok=True)

    train_loader, val_loader = get_dataloaders(
        x_path    = args.fusion_data,
        y_path    = args.labels,
        batch_size=args.batch_size,
        val_split = 0.2,
        shuffle   = True
    )

    input_dim = np.load(args.fusion_data).shape[1]
    if args.model_type == "cnn":
        model = CNNModel(input_dim=input_dim, num_classes=args.num_classes)
    else:
        model = TransformerModel(input_dim=input_dim, num_classes=args.num_classes)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)

    for epoch in range(1, args.epochs+1):
        model.train()
        total_loss = 0
        for xb, yb in train_loader:
            xb, yb = xb.to(device), yb.to(device)
            optimizer.zero_grad()
            loss = criterion(model(xb), yb)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch}, Train Loss: {total_loss/len(train_loader):.4f}")

        model.eval()
        all_preds, all_labels = [], []
        with torch.no_grad():
            for xb, yb in val_loader:
                xb, yb = xb.to(device), yb.to(device)
                preds = model(xb).argmax(dim=1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(yb.cpu().numpy())
        compute_metrics(all_labels, all_preds)
        torch.save(model.state_dict(),
                   os.path.join(args.save_dir, f"{args.model_type}_epoch{epoch}.pt"))

def main():
    args = parse_args()
    train(args)

if __name__ == "__main__":
    main()